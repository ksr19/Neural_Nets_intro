{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Урок 6. Домашнее задание","metadata":{}},{"cell_type":"markdown","source":"Импортируем необходимые библиотеки и воспользуемся кодом с урока для определения метрики, которая будет использоваться при обучении в дальнейшем.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.layers import Input, Conv2DTranspose, concatenate, Activation, MaxPooling2D, Conv2D, BatchNormalization\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras import utils\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications import VGG16\nimport numpy as np\nimport os\nfrom PIL import Image, ImageOps\nfrom sklearn.cluster import KMeans\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nimport tensorflow as tf\n\n# метрика Dice Coefficient\n\ndef dice_coef(y_true, y_pred):\n    return (2. * K.sum(y_true * y_pred) + 1.) / (K.sum(y_true) + K.sum(y_pred) + 1.)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T20:36:35.615653Z","iopub.execute_input":"2022-01-24T20:36:35.616158Z","iopub.status.idle":"2022-01-24T20:36:35.623698Z","shell.execute_reply.started":"2022-01-24T20:36:35.616122Z","shell.execute_reply":"2022-01-24T20:36:35.622801Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"markdown","source":"Будем работать с датасетом `Cityscapes`. В данном датасете присутствуют исходные и сегментированные изображения. Для построения нейросети нам нужно создать размеченные изображения, на каждом из которых будет присутствовать только один класс.","metadata":{}},{"cell_type":"code","source":"# Будем работать только с частью датасета, так как ресурсы на Kaggle ограничены\nnum_images_train = 80\nnum_images_val = 20\n\n\nX_train = []\ny_train = []\n\nX_val = []\ny_val = []\n\n\nimage_dir_train = '/kaggle/input/cityscapes-image-pairs/cityscapes_data/cityscapes_data/train'\nimage_dir_val = '/kaggle/input/cityscapes-image-pairs/cityscapes_data/cityscapes_data/val'\nimages_train = os.listdir(image_dir_train)\nimages_val = os.listdir(image_dir_val)\n\nfor filename in images_train[:num_images_train]:\n    image = Image.open(os.path.join(image_dir_train, filename))\n#     X_train.append(ImageOps.crop(image, (0, 0, 256, 0)))\n#     y_train.append(ImageOps.crop(image, (256, 0, 0, 0)))\n    X_train.append(np.asarray(ImageOps.crop(image, (0, 0, 256, 0))))\n    y_train.append(np.asarray(ImageOps.crop(image, (256, 0, 0, 0))))\n    \n\nfor filename in images_val[:num_images_val]:\n    image = Image.open(os.path.join(image_dir_val, filename))\n    X_val.append(np.asarray(ImageOps.crop(image, (0, 0, 256, 0))))\n    y_val.append(np.asarray(ImageOps.crop(image, (256, 0, 0, 0))))\n\n\nX_train = np.array(X_train) / 255.\nX_val = np.array(X_val) / 255.\n\ny_train = np.array(y_train)\ny_val = np.array(y_val)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T20:36:35.625574Z","iopub.execute_input":"2022-01-24T20:36:35.626166Z","iopub.status.idle":"2022-01-24T20:36:35.957989Z","shell.execute_reply.started":"2022-01-24T20:36:35.626059Z","shell.execute_reply":"2022-01-24T20:36:35.957117Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"markdown","source":"Построим сегментированные изображения с помощью кластеризации и затем сформируем датасет для обучения. Будем разбивать на 19 классов, так как насколько я понял из данного файла https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/helpers/labels.py в датасете 19 основных типов объектов.","metadata":{}},{"cell_type":"code","source":"num_items = 1000\ncolor_array = np.random.choice(range(256), 3*num_items).reshape(-1,3)\nnum_classes = 19\nlabel_model = KMeans(n_clusters=num_classes, random_state=21)\nlabel_model.fit(color_array)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T20:40:08.828528Z","iopub.execute_input":"2022-01-24T20:40:08.828981Z","iopub.status.idle":"2022-01-24T20:40:09.369852Z","shell.execute_reply.started":"2022-01-24T20:40:08.828947Z","shell.execute_reply":"2022-01-24T20:40:09.369064Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"label_class = label_model.predict(y_train[3].reshape(-1, 3)).reshape(256, 256)\nfig, axes = plt.subplots(1, 3, figsize=(18, 9))\naxes[0].imshow(X_train[3])\naxes[1].imshow(y_train[3])\naxes[2].imshow(label_class)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T20:40:17.029774Z","iopub.execute_input":"2022-01-24T20:40:17.030221Z","iopub.status.idle":"2022-01-24T20:40:17.555665Z","shell.execute_reply.started":"2022-01-24T20:40:17.030184Z","shell.execute_reply":"2022-01-24T20:40:17.555037Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"def Color2index(y, num_classes=19):\n    arr_col = np.arange(0, num_classes)\n    t = label_model.predict(y.reshape(-1, 3)).reshape(256, 256)\n    y_cat = (arr_col == t[...,None]).astype(int)\n    return y_cat, t\n\ncat_yi,ind_yi = Color2index(y_train[3])\n\nclass_ = 13\nfig, axes = plt.subplots(1, 2, figsize=(18, 9))\naxes[0].imshow(y_train[3,:,:,:])\naxes[0].title.set_text('Целевая разметка')\naxes[1].imshow(cat_yi[:,:,class_])\naxes[1].title.set_text(f'Целевая разметка для класса {class_}')\nplt.show() ","metadata":{"execution":{"iopub.status.busy":"2022-01-24T20:40:41.825805Z","iopub.execute_input":"2022-01-24T20:40:41.826364Z","iopub.status.idle":"2022-01-24T20:40:42.366618Z","shell.execute_reply.started":"2022-01-24T20:40:41.826317Z","shell.execute_reply":"2022-01-24T20:40:42.365964Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"markdown","source":"Сформируем наборы выходных примеров для обучения и валидации.","metadata":{}},{"cell_type":"code","source":"train_labels = []\nval_labels = []\n\nfor mask in y_train:\n    y_cat,_ = Color2index(mask)\n    train_labels.append(y_cat)\n\n\nfor mask in y_val:\n    y_cat,_ = Color2index(mask)\n    val_labels.append(y_cat)\n    \ntrain_labels = np.array(train_labels)\nval_labels = np.array(val_labels)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T20:41:01.581381Z","iopub.execute_input":"2022-01-24T20:41:01.581663Z","iopub.status.idle":"2022-01-24T20:41:02.883093Z","shell.execute_reply.started":"2022-01-24T20:41:01.581614Z","shell.execute_reply":"2022-01-24T20:41:02.882434Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"train_labels.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-24T20:41:03.469132Z","iopub.execute_input":"2022-01-24T20:41:03.469437Z","iopub.status.idle":"2022-01-24T20:41:03.476016Z","shell.execute_reply.started":"2022-01-24T20:41:03.469407Z","shell.execute_reply":"2022-01-24T20:41:03.474663Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"markdown","source":"Попробуем взять сеть с урока, немного адаптировав под условия задачи и увеличив количество эпох.","metadata":{}},{"cell_type":"code","source":"def Unet(num_classes = 19, input_shape= (256, 256, 3)):\n    img_input = Input(input_shape)\n\n    # Block 1\n    x = Conv2D(64, (3, 3), padding='same', name='block1_conv1')(img_input)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(64, (3, 3), padding='same', name='block1_conv2')(x)\n    x = BatchNormalization()(x)\n    # запомним тензор для переноса\n    block_1_out = Activation('relu')(x)\n\n    x = MaxPooling2D()(block_1_out) \n\n    # Block 2\n    x = Conv2D(128, (3, 3), padding='same', name='block2_conv1')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(128, (3, 3), padding='same', name='block2_conv2')(x)\n    x = BatchNormalization()(x)\n    # запомним тензор для переноса\n    block_2_out = Activation('relu')(x)\n\n    x = MaxPooling2D()(block_2_out) \n\n    # Block 3\n    x = Conv2D(256, (3, 3), padding='same', name='block3_conv1')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(256, (3, 3), padding='same', name='block3_conv2')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(256, (3, 3), padding='same', name='block3_conv3')(x)\n    x = BatchNormalization()(x)\n    # запомним тензор для переноса\n    block_3_out = Activation('relu')(x)\n\n    x = MaxPooling2D()(block_3_out) \n\n    # Block 4\n    x = Conv2D(512, (3, 3), padding='same', name='block4_conv1')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(512, (3, 3), padding='same', name='block4_conv2')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(512, (3, 3), padding='same', name='block4_conv3')(x)\n    x = BatchNormalization()(x)\n    # запомним тензор для переноса\n    block_4_out = Activation('relu')(x)\n\n    # UP 1\n    x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    # добавили перенос из понижаюшего плеча\n    x = concatenate([x, block_3_out])\n    x = Conv2D(256, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(256, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    # UP 2\n    x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x) \n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    # добавили перенос из понижаюшего плеча\n    x = concatenate([x, block_2_out])\n    x = Conv2D(128, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(128, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    # UP 3\n    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    # добавили перенос из понижаюшего плеча\n    x = concatenate([x, block_1_out])\n    x = Conv2D(64, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(64, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n\n    # слой классификатор\n    x = Conv2D(num_classes, (3, 3), activation='softmax', padding='same')(x)\n\n    model = Model(img_input, x)\n    model.compile(optimizer=Adam(),\n                  loss='categorical_crossentropy',\n                  metrics=[dice_coef])\n    model.summary()\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-24T20:41:06.205423Z","iopub.execute_input":"2022-01-24T20:41:06.205701Z","iopub.status.idle":"2022-01-24T20:41:06.228803Z","shell.execute_reply.started":"2022-01-24T20:41:06.205671Z","shell.execute_reply":"2022-01-24T20:41:06.227682Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"model_1 = Unet(19, (256, 256, 3))\n\nplot_model(model_1, to_file='model_1.png', show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T20:41:07.989288Z","iopub.execute_input":"2022-01-24T20:41:07.989540Z","iopub.status.idle":"2022-01-24T20:41:09.118299Z","shell.execute_reply.started":"2022-01-24T20:41:07.989511Z","shell.execute_reply":"2022-01-24T20:41:09.117543Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"history = model_1.fit(X_train, train_labels, epochs=25, batch_size=1, validation_data=(X_val, val_labels))","metadata":{"execution":{"iopub.status.busy":"2022-01-24T20:41:10.352742Z","iopub.execute_input":"2022-01-24T20:41:10.353510Z","iopub.status.idle":"2022-01-24T20:43:35.924785Z","shell.execute_reply.started":"2022-01-24T20:41:10.353472Z","shell.execute_reply":"2022-01-24T20:43:35.923878Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(18, 9))\nplt.plot(history.history['val_dice_coef'],label = 'test')\nplt.plot(history.history['dice_coef'],label='train')\nplt.legend()\nplt.xlabel('epoch')\nplt.ylabel('dice_coef')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T20:44:15.957355Z","iopub.execute_input":"2022-01-24T20:44:15.957611Z","iopub.status.idle":"2022-01-24T20:44:16.199145Z","shell.execute_reply.started":"2022-01-24T20:44:15.957583Z","shell.execute_reply":"2022-01-24T20:44:16.198482Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"markdown","source":"Видим, что метрика на тесте ведет себя очень нестабильно, в то время как на трейне метрика растет, что в конечном итоге на более поздних эпохах ведет к заметному переобучению. Посмотрим насколько хорошо получается разметка для отдельных классов.","metadata":{}},{"cell_type":"code","source":"pred = model_1.predict(X_val)\nprint(pred.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T20:45:24.371021Z","iopub.execute_input":"2022-01-24T20:45:24.371284Z","iopub.status.idle":"2022-01-24T20:45:25.199076Z","shell.execute_reply.started":"2022-01-24T20:45:24.371253Z","shell.execute_reply":"2022-01-24T20:45:25.198146Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"class_ = 13\nfig, axes = plt.subplots(1, 4, figsize=(18, 9))\naxes[0].imshow(X_val[5])\naxes[0].title.set_text('входной кадр')\naxes[1].imshow(y_val[5])\naxes[1].title.set_text('целевая разметка')\naxes[2].imshow(val_labels[5][:,:,class_])\naxes[2].title.set_text(f'целевая разметка класс: {class_}')\naxes[3].imshow(pred[5][:,:,class_])\naxes[3].title.set_text(f'предиктивная разметка класс: {class_}')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T20:45:32.550835Z","iopub.execute_input":"2022-01-24T20:45:32.551373Z","iopub.status.idle":"2022-01-24T20:45:33.106277Z","shell.execute_reply.started":"2022-01-24T20:45:32.551336Z","shell.execute_reply":"2022-01-24T20:45:33.105645Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"markdown","source":"Попробуем улучшить модель:\n\n* изменим функцию активации;\n* добавим специфичное определение начальных весов;\n* изменим оптимизатор и зададим коэффициент скорости обучения;\n* увеличим количество эпох обучения.","metadata":{}},{"cell_type":"code","source":"def Unet(num_classes = 19, input_shape= (256, 256, 3)):\n    img_input = Input(input_shape)\n\n    # Block 1\n    x = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', name='block1_conv1')(img_input)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', name='block1_conv2')(x)\n    x = BatchNormalization()(x)\n    # запомним тензор для переноса\n    block_1_out = Activation('LeakyReLU')(x)\n\n    x = MaxPooling2D()(block_1_out) \n\n    # Block 2\n    x = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal', name='block2_conv1')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal', name='block2_conv2')(x)\n    x = BatchNormalization()(x)\n    # запомним тензор для переноса\n    block_2_out = Activation('LeakyReLU')(x)\n\n    x = MaxPooling2D()(block_2_out) \n\n    # Block 3\n    x = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', name='block3_conv1')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', name='block3_conv2')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', name='block3_conv3')(x)\n    x = BatchNormalization()(x)\n    # запомним тензор для переноса\n    block_3_out = Activation('LeakyReLU')(x)\n\n    x = MaxPooling2D()(block_3_out) \n\n    # Block 4\n    x = Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal', name='block4_conv1')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal', name='block4_conv2')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal', name='block4_conv3')(x)\n    x = BatchNormalization()(x)\n    # запомним тензор для переноса\n    block_4_out = Activation('LeakyReLU')(x)\n\n#     x = MaxPooling2D()(block_4_out)\n\n#     Block 5\n#     x = Conv2D(512, (3, 3), padding='same', name='block5_conv1')(x)\n#     x = BatchNormalization()(x)\n#     x = Activation('relu')(x)\n\n#     x = Conv2D(512, (3, 3), padding='same', name='block5_conv2')(x)\n#     x = BatchNormalization()(x)\n#     x = Activation('relu')(x)\n\n#     x = Conv2D(512, (3, 3), padding='same', name='block5_conv3')(x)\n#     x = BatchNormalization()(x)\n#     x = Activation('relu')(x)\n\n\n    # Load pretrained weights.\n    #for_pretrained_weight = MaxPooling2D()(x)\n    #vgg16 = Model(img_input, for_pretrained_weight)\n    #vgg16.load_weights('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', by_name=True)\n\n    # UP 1\n#     x = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(x)\n#     x = BatchNormalization()(x)\n#     x = Activation('relu')(x)\n\n#     x = concatenate([x, block_4_out])\n#     x = Conv2D(512, (3, 3), padding='same')(x)\n#     x = BatchNormalization()(x)\n#     x = Activation('relu')(x)\n\n#     x = Conv2D(512, (3, 3), padding='same')(x)\n#     x = BatchNormalization()(x)\n#     x = Activation('relu')(x)\n\n    # UP 2\n    x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    # добавили перенос из понижаюшего плеча\n    x = concatenate([x, block_3_out])\n    x = Conv2D(256, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = Conv2D(256, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    # UP 3\n    x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x) \n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    # добавили перенос из понижаюшего плеча\n    x = concatenate([x, block_2_out])\n    x = Conv2D(128, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = Conv2D(128, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    # UP 4\n    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x) # 200x600\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    # добавили перенос из понижаюшего плеча\n    x = concatenate([x, block_1_out])\n    x = Conv2D(64, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = Conv2D(64, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    # слой классификатор\n    x = Conv2D(num_classes, (3, 3), activation='softmax', padding='same')(x)\n\n    model = Model(img_input, x)\n    model.compile(optimizer=SGD(learning_rate=1e-2),\n                  loss='categorical_crossentropy',\n                  metrics=[dice_coef])\n    model.summary()\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-24T20:50:39.383569Z","iopub.execute_input":"2022-01-24T20:50:39.384008Z","iopub.status.idle":"2022-01-24T20:50:39.410028Z","shell.execute_reply.started":"2022-01-24T20:50:39.383974Z","shell.execute_reply":"2022-01-24T20:50:39.409223Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"code","source":"model_2 = Unet(19, (256, 256, 3))\n\n# plot_model(model_2, to_file='model_2.png', show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T20:50:39.802333Z","iopub.execute_input":"2022-01-24T20:50:39.802882Z","iopub.status.idle":"2022-01-24T20:50:40.192697Z","shell.execute_reply.started":"2022-01-24T20:50:39.802843Z","shell.execute_reply":"2022-01-24T20:50:40.191983Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"def callbacks(patience=5):\n    checkpoint = tf.keras.callbacks.ModelCheckpoint('seg_model.h5', monitor='loss', verbose=1, save_best_only=True, save_weights_only=True)\n    early=tf.keras.callbacks.EarlyStopping(monitor='loss',patience=patience)\n    callbacks_list=[checkpoint, early]\n    return callbacks_list\n\n\nhistory = model_2.fit(X_train, train_labels, epochs=50, batch_size=1, validation_data=(X_val, val_labels), callbacks=callbacks())","metadata":{"execution":{"iopub.status.busy":"2022-01-24T20:50:45.099468Z","iopub.execute_input":"2022-01-24T20:50:45.100007Z","iopub.status.idle":"2022-01-24T20:54:10.745510Z","shell.execute_reply.started":"2022-01-24T20:50:45.099972Z","shell.execute_reply":"2022-01-24T20:54:10.744730Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(18, 9))\nplt.plot(history.history['val_dice_coef'],label = 'test')\nplt.plot(history.history['dice_coef'],label='train')\nplt.legend()\nplt.xlabel('epoch')\nplt.ylabel('dice_coef')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T20:54:14.348608Z","iopub.execute_input":"2022-01-24T20:54:14.348875Z","iopub.status.idle":"2022-01-24T20:54:14.591635Z","shell.execute_reply.started":"2022-01-24T20:54:14.348846Z","shell.execute_reply":"2022-01-24T20:54:14.590963Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"markdown","source":"Метрика на тесте для данной модели ведет себя более стабильно и в среднем находится на более высоком уровне, чем в изначальной. На поздних этапах снова заметно переобучение.","metadata":{}},{"cell_type":"code","source":"pred = model_2.predict(X_val)\n\nclass_ = 13\nfig, axes = plt.subplots(1, 4, figsize=(18, 9))\naxes[0].imshow(X_val[5])\naxes[0].title.set_text('входной кадр')\naxes[1].imshow(y_val[5])\naxes[1].title.set_text('целевая разметка')\naxes[2].imshow(val_labels[5][:,:,class_])\naxes[2].title.set_text('целевая разметка класс: '+str(class_))\naxes[3].imshow(pred[5][:,:,class_])\naxes[3].title.set_text('предиктивная разметка класс: '+str(class_))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T20:57:31.082744Z","iopub.execute_input":"2022-01-24T20:57:31.083403Z","iopub.status.idle":"2022-01-24T20:57:32.310313Z","shell.execute_reply.started":"2022-01-24T20:57:31.083360Z","shell.execute_reply":"2022-01-24T20:57:32.309588Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"markdown","source":"Сделаем еще одну итерацию модели - поменяем количество ядер, добавим еще одну пару слоев и, наконец, увеличим размер батча.","metadata":{}},{"cell_type":"code","source":"def Unet(num_classes = 19, input_shape= (256, 256, 3)):\n    img_input = Input(input_shape)\n\n    # Block 1\n    x = Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal', name='block1_conv1')(img_input)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal', name='block1_conv2')(x)\n    x = BatchNormalization()(x)\n    # запомним тензор для переноса\n    block_1_out = Activation('LeakyReLU')(x)\n\n    x = MaxPooling2D()(block_1_out) \n\n    # Block 2\n    x = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', name='block2_conv1')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', name='block2_conv2')(x)\n    x = BatchNormalization()(x)\n    # запомним тензор для переноса\n    block_2_out = Activation('LeakyReLU')(x)\n\n    x = MaxPooling2D()(block_2_out) \n\n    # Block 3\n    x = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal', name='block3_conv1')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal', name='block3_conv2')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal', name='block3_conv3')(x)\n    x = BatchNormalization()(x)\n    # запомним тензор для переноса\n    block_3_out = Activation('LeakyReLU')(x)\n\n    x = MaxPooling2D()(block_3_out) \n\n    # Block 4\n    x = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', name='block4_conv1')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', name='block4_conv2')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = Conv2D(256, (3, 3), padding='same', kernel_initializer='he_normal', name='block4_conv3')(x)\n    x = BatchNormalization()(x)\n    # запомним тензор для переноса\n    block_4_out = Activation('LeakyReLU')(x)\n\n    x = MaxPooling2D()(block_4_out)\n\n#     Block 5\n    x = Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal', name='block5_conv1')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal', name='block5_conv2')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal', name='block5_conv3')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n\n    # Load pretrained weights.\n    #for_pretrained_weight = MaxPooling2D()(x)\n    #vgg16 = Model(img_input, for_pretrained_weight)\n    #vgg16.load_weights('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', by_name=True)\n\n#     UP 1\n    x = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = concatenate([x, block_4_out])\n    x = Conv2D(512, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = Conv2D(512, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    # UP 2\n    x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    # добавили перенос из понижаюшего плеча\n    x = concatenate([x, block_3_out])\n    x = Conv2D(256, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = Conv2D(256, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    # UP 3\n    x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x) \n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    # добавили перенос из понижаюшего плеча\n    x = concatenate([x, block_2_out])\n    x = Conv2D(128, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = Conv2D(128, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    # UP 4\n    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x) # 200x600\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    # добавили перенос из понижаюшего плеча\n    x = concatenate([x, block_1_out])\n    x = Conv2D(64, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    x = Conv2D(64, (3, 3), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = Activation('LeakyReLU')(x)\n\n    # слой классификатор\n    x = Conv2D(num_classes, (1, 1), activation='softmax', padding='same')(x)\n\n    model = Model(img_input, x)\n    model.compile(optimizer=SGD(learning_rate=1e-2),\n                  loss='categorical_crossentropy',\n                  metrics=[dice_coef])\n    model.summary()\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-24T21:16:10.698146Z","iopub.execute_input":"2022-01-24T21:16:10.698403Z","iopub.status.idle":"2022-01-24T21:16:10.729572Z","shell.execute_reply.started":"2022-01-24T21:16:10.698374Z","shell.execute_reply":"2022-01-24T21:16:10.728801Z"},"trusted":true},"execution_count":166,"outputs":[]},{"cell_type":"code","source":"model_3 = Unet(19, (256, 256, 3))\n\n# plot_model(model_3, to_file='model_3.png', show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T21:16:11.960578Z","iopub.execute_input":"2022-01-24T21:16:11.961120Z","iopub.status.idle":"2022-01-24T21:16:12.472102Z","shell.execute_reply.started":"2022-01-24T21:16:11.961083Z","shell.execute_reply":"2022-01-24T21:16:12.471306Z"},"trusted":true},"execution_count":167,"outputs":[]},{"cell_type":"code","source":"def callbacks(patience=5):\n    checkpoint = tf.keras.callbacks.ModelCheckpoint('seg_model_3.h5', monitor='loss', verbose=1, save_best_only=True, save_weights_only=True)\n    early=tf.keras.callbacks.EarlyStopping(monitor='loss',patience=patience)\n    callbacks_list=[checkpoint, early]\n    return callbacks_list\n\n\nhistory = model_3.fit(X_train, train_labels, epochs=50, batch_size=2, validation_data=(X_val, val_labels), callbacks=callbacks())","metadata":{"execution":{"iopub.status.busy":"2022-01-24T21:16:13.608884Z","iopub.execute_input":"2022-01-24T21:16:13.609135Z","iopub.status.idle":"2022-01-24T21:18:59.040151Z","shell.execute_reply.started":"2022-01-24T21:16:13.609107Z","shell.execute_reply":"2022-01-24T21:18:59.038349Z"},"trusted":true},"execution_count":168,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(18, 9))\nplt.plot(history.history['val_dice_coef'],label = 'test')\nplt.plot(history.history['dice_coef'],label='train')\nplt.legend()\nplt.xlabel('epoch')\nplt.ylabel('dice_coef')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T21:20:11.353050Z","iopub.execute_input":"2022-01-24T21:20:11.354445Z","iopub.status.idle":"2022-01-24T21:20:11.587592Z","shell.execute_reply.started":"2022-01-24T21:20:11.354396Z","shell.execute_reply":"2022-01-24T21:20:11.586971Z"},"trusted":true},"execution_count":169,"outputs":[]},{"cell_type":"markdown","source":"По моему мнению эта модель лучше предыдущих, метрика на тесте довольно стабильна, переобучение значительно сократилось. Из негативных факторов возросшое количество параметров для обучения.","metadata":{}},{"cell_type":"code","source":"pred = model_3.predict(X_val)\n\nclass_ = 13\nfig, axes = plt.subplots(1, 4, figsize=(18, 9))\naxes[0].imshow(X_val[5])\naxes[0].title.set_text('входной кадр')\naxes[1].imshow(y_val[5])\naxes[1].title.set_text('целевая разметка')\naxes[2].imshow(val_labels[5][:,:,class_])\naxes[2].title.set_text('целевая разметка класс: '+str(class_))\naxes[3].imshow(pred[5][:,:,class_])\naxes[3].title.set_text('предиктивная разметка класс: '+str(class_))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-24T21:24:25.836049Z","iopub.execute_input":"2022-01-24T21:24:25.836311Z","iopub.status.idle":"2022-01-24T21:25:04.608919Z","shell.execute_reply.started":"2022-01-24T21:24:25.836282Z","shell.execute_reply":"2022-01-24T21:25:04.608288Z"},"trusted":true},"execution_count":170,"outputs":[]},{"cell_type":"markdown","source":"Итоговые результаты тестирования разных моделей:","metadata":{}},{"cell_type":"markdown","source":"|   | Параметры | Эпохи  | Train_Loss  | Val_loss  | Train_dice_coeff | Val_dice_coeff |\n|---|---|---|---|---|---|---|\n| Модель 1  | 10,674,259  | 25  |  0.6945 | 1.3464 | 0.6989  | 0.5630  |\n| Модель 2  |  10,674,259 | 50  |  **0.3564** | 1.1708 | **0.8359**  | 0.6401  |\n| Модель 3  | 17,407,155  | 50  |  0.5261 | **0.9735** | 0.7693  | **0.6679**  |","metadata":{}}]}